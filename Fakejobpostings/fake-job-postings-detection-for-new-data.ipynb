{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7440206,"sourceType":"datasetVersion","datasetId":4330414},{"sourceId":7441544,"sourceType":"datasetVersion","datasetId":4331287}],"dockerImageVersionId":30635,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Create an empty a df_new_data DataFrame for storing the user input history\n\n#df_new_data = pd.DataFrame(columns=['role', 'location', 'job_description'])","metadata":{"execution":{"iopub.status.busy":"2024-01-20T14:21:27.992259Z","iopub.execute_input":"2024-01-20T14:21:27.993504Z","iopub.status.idle":"2024-01-20T14:21:27.999149Z","shell.execute_reply.started":"2024-01-20T14:21:27.993461Z","shell.execute_reply":"2024-01-20T14:21:27.997732Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"# Download the lexicon\nimport nltk\nfrom nltk.corpus import opinion_lexicon\n\n# Get positive and negative words from the lexicon\npositive_words = set(opinion_lexicon.positive())\nnegative_words = set(opinion_lexicon.negative())","metadata":{"execution":{"iopub.status.busy":"2024-01-20T14:28:03.481239Z","iopub.execute_input":"2024-01-20T14:28:03.481680Z","iopub.status.idle":"2024-01-20T14:28:03.512942Z","shell.execute_reply.started":"2024-01-20T14:28:03.481643Z","shell.execute_reply":"2024-01-20T14:28:03.512065Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"import pickle\nimport pandas as pd\nimport numpy as np\nimport nltk\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom concurrent.futures import ProcessPoolExecutor\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.metrics import precision_recall_curve\nimport matplotlib.pyplot as plt\n\n# Welcome message\nprint(\"Welcome aboard! Let's navigate through job postings and identify the authentic ones.\\nInput the job information to begin!\\n\")\n\n\n# Load the Model back from file\nPkl_Filename = \"/kaggle/input/pkl-file-model-with-preprocesssing/Fake_Job_Postings_Detection_with_preprocessing.pkl\"\nwith open(Pkl_Filename, 'rb') as file:  \n    loaded_model_data = pickle.load(file)\n\n# Extract the loaded data\nloaded_ensemble_model = loaded_model_data['model']\ntfidf_vectorizer = loaded_model_data['tfidf_vectorizer']\nscaler = loaded_model_data['scaler']\nmin_max_scaler = loaded_model_data['min_max_scaler']\nnumeric_columns = loaded_model_data['numeric_columns']\noptimal_threshold_new_data = loaded_model_data['optimal_threshold_new_data']\n\n# Create or load df_new_data\ntry:\n    df_new_data = pd.read_csv(\"df_new_data.csv\")\nexcept FileNotFoundError:\n    df_new_data = pd.DataFrame(columns=['role', 'location', 'job_description', 'combined_text', 'fraudulent', 'positive_score', 'negative_score'])\n\n# Assuming df_new_data has columns: 'role', 'location', 'job_description'\n# Get user input for new entries\nuser_role = input(\"Enter the role: \")\nuser_location = input(\"Enter the location: \")\nuser_job_description = input(\"Enter the job description: \")\n\n# Create a new entry DataFrame with the user input\nnew_entry = pd.DataFrame({\n    'role': [user_role],\n    'location': [user_location],\n    'job_description': [user_job_description]\n})\n\n# If needed, fill any missing values in the new entry\nnew_entry = new_entry.fillna('')\n\n# Combine 'role', 'location', and 'job_description' into a single column\nnew_entry['combined_text'] = new_entry['role'] + ' ' + new_entry['location'] + ' ' + new_entry['job_description']\n\n# Calculate sentiment scores using the provided function\ndef calculate_sentiment_scores(row):\n    tokens = word_tokenize(row['combined_text'])\n    positive_score = np.sum(np.isin(tokens, list(positive_words)))\n    negative_score = np.sum(np.isin(tokens, list(negative_words)))\n    return pd.Series({'positive_score': positive_score, 'negative_score': negative_score})\n\n# Apply sentiment analysis to the new entry\nnew_entry[['positive_score', 'negative_score']] = new_entry.apply(calculate_sentiment_scores, axis=1)\n\n# Create additional features: 'desc_num_char', 'desc_num_words', 'desc_num_sent'\nnew_entry['desc_num_char'] = new_entry['combined_text'].apply(len)\nnew_entry['desc_num_words'] = new_entry['combined_text'].apply(lambda x: len(x.split()))\nnew_entry['desc_num_sent'] = new_entry['combined_text'].apply(lambda x: len(nltk.sent_tokenize(x)))\n\n# Create a DataFrame with numeric features\nX_numeric_new_entry = new_entry[['positive_score', 'negative_score', 'desc_num_char', 'desc_num_words', 'desc_num_sent']]\n\n# Combine text TF-IDF vectors with numeric features\nX_text_new_entry_tfidf = tfidf_vectorizer.transform(new_entry['combined_text'])\nX_new_entry = pd.concat([X_numeric_new_entry, pd.DataFrame(X_text_new_entry_tfidf.toarray())], axis=1)\n\n# Standardize numeric features\nX_new_entry.iloc[:, :5] = scaler.transform(X_new_entry.iloc[:, :5])\n\n# Apply Min-Max scaling to numeric features\nX_new_entry[numeric_columns] = min_max_scaler.transform(X_new_entry[numeric_columns])\n\n# Convert feature names to strings\nX_new_entry.columns = X_new_entry.columns.astype(str)\n\n# Predict probabilities for the new entry using the loaded ensemble model\ny_pred_prob_new_entry = loaded_ensemble_model.predict_proba(X_new_entry)[:, 1]\n\n# Apply optimal threshold\ny_pred_new_entry = (y_pred_prob_new_entry > optimal_threshold_new_data).astype(int)\n\n# Calculate sentiment scores for the new entry\nnew_entry[['positive_score', 'negative_score']] = new_entry.apply(calculate_sentiment_scores, axis=1)\n\n# Append the new entry to the existing df_new_data\nnew_entry['fraudulent'] = y_pred_new_entry\ndf_new_data = pd.concat([df_new_data, new_entry], ignore_index=True)\n\n# Save df_new_data to a CSV file\ndf_new_data.to_csv(\"df_new_data.csv\", index=False)\n\n# Display or use the predictions for the new entry\nprint(\"\\nPredictions for the New Entry:\")\nprint(y_pred_new_entry)\n# Print statements based on prediction\nif y_pred_new_entry[0] == 1:\n    print(\"Entered Job posting is Fake\")\nelse:\n    print(\"Entered Job posting is Real\")","metadata":{"execution":{"iopub.status.busy":"2024-01-20T14:34:48.061470Z","iopub.execute_input":"2024-01-20T14:34:48.061888Z","iopub.status.idle":"2024-01-20T14:35:12.037560Z","shell.execute_reply.started":"2024-01-20T14:34:48.061847Z","shell.execute_reply":"2024-01-20T14:35:12.036378Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"Welcome aboard! Let's navigate through job postings and identify the authentic ones.\nInput the job information to begin!\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter the role:   Administrative Assistant\nEnter the location:  US, CA, San Francisco\nEnter the job description:  The Administrative Assistant will be based in San Francisco, CA. The right candidate will be an inte...\n"},{"name":"stdout","text":"\nPredictions for the New Entry:\n[0]\nEntered Job posting is Real\n","output_type":"stream"}]},{"cell_type":"code","source":"df_new_data","metadata":{"execution":{"iopub.status.busy":"2024-01-20T14:35:17.470781Z","iopub.execute_input":"2024-01-20T14:35:17.471425Z","iopub.status.idle":"2024-01-20T14:35:17.487892Z","shell.execute_reply.started":"2024-01-20T14:35:17.471389Z","shell.execute_reply":"2024-01-20T14:35:17.486389Z"},"trusted":true},"execution_count":76,"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"                                  role               location  \\\n0                                    d                      d   \n1  WAH Customer Service Repersentative       US, SC, Columbia   \n2             Administrative Assistant  US, CA, San Francisco   \n\n                                     job_description  \\\n0                                                  d   \n1  ECHO HEIGHT LLC (WORK AT HOME) is now exceptin...   \n2  The Administrative Assistant will be based in ...   \n\n                                       combined_text  fraudulent  \\\n0                                              d d d           0   \n1  WAH Customer Service Repersentative US, SC, Co...           1   \n2   Administrative Assistant US, CA, San Francisc...           0   \n\n   positive_score  negative_score  desc_num_char  desc_num_words  \\\n0               0               0            5.0             3.0   \n1               1               0          156.0            23.0   \n2               1               0          151.0            23.0   \n\n   desc_num_sent  \n0            1.0  \n1            1.0  \n2            2.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>role</th>\n      <th>location</th>\n      <th>job_description</th>\n      <th>combined_text</th>\n      <th>fraudulent</th>\n      <th>positive_score</th>\n      <th>negative_score</th>\n      <th>desc_num_char</th>\n      <th>desc_num_words</th>\n      <th>desc_num_sent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>d</td>\n      <td>d</td>\n      <td>d</td>\n      <td>d d d</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>WAH Customer Service Repersentative</td>\n      <td>US, SC, Columbia</td>\n      <td>ECHO HEIGHT LLC (WORK AT HOME) is now exceptin...</td>\n      <td>WAH Customer Service Repersentative US, SC, Co...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>156.0</td>\n      <td>23.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Administrative Assistant</td>\n      <td>US, CA, San Francisco</td>\n      <td>The Administrative Assistant will be based in ...</td>\n      <td>Administrative Assistant US, CA, San Francisc...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>151.0</td>\n      <td>23.0</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"        ","metadata":{},"execution_count":null,"outputs":[]}]}